{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VR-aozjuNBkn"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import optim, nn\n",
    "from modules.dataset import *\n",
    "from modules.network import *\n",
    "from modules.embeddings import *\n",
    "from torch import save, device, cuda\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Y86jEOjaNBku",
    "outputId": "52f708ff-1c3a-406b-bdab-1cd5b31788d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = device(\"cuda\") if cuda.is_available() else device(\"cpu\")\n",
    "print('Selected device:', device)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Colab packages\n",
    "from google.colab import files, drive\n",
    "\n",
    "# Connect drive to colab\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directories (Colab)\n",
    "!mkdir ./dataset\n",
    "!mkdir ./drive/My\\ Drive/Colab\\ Notebooks/images\n",
    "!mkdir ./drive/My\\ Drive/Colab\\ Notebooks/results\n",
    "!mkdir ./drive/My\\ Drive/Colab\\ Notebooks/results/losses\n",
    "\n",
    "# Set paths\n",
    "images_path = \"./drive/My Drive/Colab Notebooks/images\"\n",
    "res_path = \"./drive/My Drive/Colab Notebooks/results/losses\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set local paths\n",
    "images_path = \"./images\"\n",
    "res_path = \"./data/losses\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NBpduFYANBkz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "466"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%Loading the dataset \n",
    "\n",
    "min_len = 10\n",
    "dataset = Mobydick('./data/mobydick.txt', min_len = min_len)\n",
    "\n",
    "with open('./data/clean_text', 'wb') as f:\n",
    "    pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['some', 'years', 'ago', 'never', 'mind', 'how', 'long', 'precisely', 'having', 'little', 'or', 'no', 'money', 'in', 'my', 'purse', ',', 'and', 'nothing', 'particular', 'to', 'interest', 'me', 'on', 'shore', ',', 'i', 'thought', 'i', 'would', 'sail', 'about', 'a', 'little', 'and', 'see', 'the', 'watery', 'part', 'of', 'the', 'world', '.']\n"
     ]
    }
   ],
   "source": [
    "# Given a min_len>2, it is not necessary to delete the chapters titles\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean sentence length: 30.446351931330472\n",
      "Max sentence length: 127\n",
      "Min sentence length: 10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset visualization\n",
    "lengths = [ len(sentence)  for sentence in dataset ]\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14,6))\n",
    "axs.ravel()\n",
    "axs[0].set_title('Sentence length values')\n",
    "axs[0].set_xlabel('sentence index')\n",
    "axs[0].set_ylabel('sentence length')\n",
    "_ = axs[0].plot(lengths, '.')\n",
    "axs[1].set_title('Sentence length distribution')\n",
    "axs[1].set_xlabel('sentence length')\n",
    "axs[1].set_ylabel('length probability')\n",
    "_ = axs[1].hist(lengths, bins=40, density=True)\n",
    "\n",
    "print('Mean sentence length:', np.mean(lengths))\n",
    "print('Max sentence length:', np.max(lengths))\n",
    "print('Min sentence length:', np.min(lengths))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(images_path+f'/md_{min_len}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14188\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset.words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the embedding dimension\n",
    "embedding_dim = 50\n",
    "\n",
    "# Copy dataset words\n",
    "words = set(dataset.words.copy())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time \n",
    "\n",
    "# Load embeddings from glove\n",
    "glove = from_file(path='data/glove.6B.50d.txt',\n",
    "                  words=words\n",
    "                 )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Analyse glove embeddings\n",
    "print('Mean:', np.mean(list(glove.values())), ', STD: ', np.std(list(glove.values())) )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define embeddings for unknown words by sampling from normal distirbution, using found parameters\n",
    "mean = np.mean(list(glove.values()))\n",
    "std = np.std(list(glove.values())) \n",
    "\n",
    "# Initialize randomly sampled embeddings\n",
    "embeddings = gaussian_sampling(mean, std, dim=embedding_dim, words=words)\n",
    "# Loop through each embedded word\n",
    "for word, vector in embeddings.items():\n",
    "    # Subsititute current entry with glove one, if available\n",
    "    embeddings[word] = glove.get(word, vector)\n",
    "\n",
    "# Get list of words\n",
    "words = [*embeddings.keys()]\n",
    "# Get vectors as float tensor\n",
    "vectors = torch.tensor([*embeddings.values()], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Analyse generated embeddings\n",
    "print('Mean:', np.mean(list(embeddings.values())), ', STD: ', np.std(list(embeddings.values())) )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a = vectors.shape[0] # obtained with all words in vocab and in glove + words in vocab not in glove\n",
    "b = len(set(glove.keys()) & set(dataset.words)) + len(set(dataset.words) - set(glove.keys())) \n",
    "# sanity check\n",
    "a == b"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('./data/embeddings', 'wb') as f:\n",
    "    pickle.dump(embeddings, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "with open('./data/embeddings', 'rb') as f:\n",
    "    embeddings = pickle.load(f)\n",
    "\n",
    "# Get list of words\n",
    "words = [*embeddings.keys()]\n",
    "# Get vectors as float tensor\n",
    "vectors = torch.tensor([*embeddings.values()], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_len = 8\n",
    "\n",
    "# Define transformation \n",
    "dataset.transform = transforms.Compose([\n",
    "    RandomCrop(crop_len),\n",
    "    WordToVector(words),\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defined the transform, this call returns the word index (after random cropping)\n",
    "dataset[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ZNAdwzKNBkr"
   },
   "outputs": [],
   "source": [
    "##Parameters\n",
    "\n",
    "params = {\n",
    "        # network\n",
    "        'hidden_units' : 2**8, # symmetric layers\n",
    "        'layers_num' : 2,\n",
    "        'dropout_prob' : 0.4,\n",
    "\n",
    "        # training\n",
    "        'batch_size' : 100,\n",
    "        'num_epochs' : 400,\n",
    "\n",
    "        # optimizer\n",
    "        'lr' : 1e-2,\n",
    "        'wd' : 1e-3,\n",
    "    \n",
    "        # dataset\n",
    "        'crop_len' : crop_len,\n",
    "        'min_len' : min_len\n",
    "        }\n",
    "\n",
    "# save\n",
    "out_dir = f'LSTM_{crop_len}_{min_len}'+'_{}_{}'.format(params['lr'],params['wd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split initial dataset in train dataset and test dataset\n",
    "train_dataset, test_dataset = split_train_test(dataset, 0.9)\n",
    "# Make train dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "# Make test dataloader\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oc8u0owgNBk2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (rnn): LSTM(50, 256, num_layers=2, batch_first=True, dropout=0.4)\n",
       "  (out): Linear(in_features=256, out_features=50, bias=True)\n",
       "  (embed): Embedding(2998, 50)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: hyperparameter optimization, this part must be included in the GridSearch iteration\n",
    "\n",
    "#%% Initialize network\n",
    "net = Network(vocab_size = vectors.shape[0],\n",
    "              embedding_dim = embedding_dim,\n",
    "              hidden_units = params['hidden_units'],\n",
    "              layers_num = params['layers_num'],\n",
    "              hidden_type = 'LSTM',\n",
    "              trained_embeddings = vectors,\n",
    "              dropout_prob = params['dropout_prob']\n",
    "             )\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=params['lr'], weight_decay=params['wd'])\n",
    "# Define loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.NLLLoss()\n",
    "\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "colab_type": "code",
    "id": "1ChGVuPFNBk5",
    "outputId": "49d215e0-67b4-4022-f23b-69bbca522b94",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " EPOCH 1/400\n",
      "\t Training loss (epoch - mean):  0.604346489906311\n",
      "\t Validation loss (epoch - mean): 0.2909357246566326\n",
      "\n",
      "\n",
      " EPOCH 2/400\n",
      "\t Training loss (epoch - mean):  0.2659580856561661\n",
      "\t Validation loss (epoch - mean): 0.175277053834276\n",
      "\n",
      "\n",
      " EPOCH 3/400\n",
      "\t Training loss (epoch - mean):  0.20076326429843902\n",
      "\t Validation loss (epoch - mean): 0.18082856640536735\n",
      "\n",
      "\n",
      " EPOCH 4/400\n",
      "\t Training loss (epoch - mean):  0.17434098422527314\n",
      "\t Validation loss (epoch - mean): 0.14016363880735763\n",
      "\n",
      "\n",
      " EPOCH 5/400\n",
      "\t Training loss (epoch - mean):  0.15322765707969666\n",
      "\t Validation loss (epoch - mean): 0.1190416602853765\n",
      "\n",
      "\n",
      " EPOCH 6/400\n",
      "\t Training loss (epoch - mean):  0.12382156550884246\n",
      "\t Validation loss (epoch - mean): 0.11382736210176285\n",
      "\n",
      "\n",
      " EPOCH 7/400\n",
      "\t Training loss (epoch - mean):  0.11108192652463914\n",
      "\t Validation loss (epoch - mean): 0.13354053019367634\n",
      "\n",
      "\n",
      " EPOCH 8/400\n",
      "\t Training loss (epoch - mean):  0.11069621592760086\n",
      "\t Validation loss (epoch - mean): 0.09671231386984916\n",
      "\n",
      "\n",
      " EPOCH 9/400\n",
      "\t Training loss (epoch - mean):  0.09101707190275192\n",
      "\t Validation loss (epoch - mean): 0.07914128106959323\n",
      "\n",
      "\n",
      " EPOCH 10/400\n",
      "\t Training loss (epoch - mean):  0.08256372213363647\n",
      "\t Validation loss (epoch - mean): 0.07196127193326012\n",
      "\n",
      "\n",
      " EPOCH 11/400\n",
      "\t Training loss (epoch - mean):  0.08040701895952225\n",
      "\t Validation loss (epoch - mean): 0.07778605410551771\n",
      "\n",
      "\n",
      " EPOCH 12/400\n",
      "\t Training loss (epoch - mean):  0.078078493475914\n",
      "\t Validation loss (epoch - mean): 0.05438599039978804\n",
      "\n",
      "\n",
      " EPOCH 13/400\n",
      "\t Training loss (epoch - mean):  0.07006867527961731\n",
      "\t Validation loss (epoch - mean): 0.05639435457897947\n",
      "\n",
      "\n",
      " EPOCH 14/400\n",
      "\t Training loss (epoch - mean):  0.05937625467777252\n",
      "\t Validation loss (epoch - mean): 0.04374062333335268\n",
      "\n",
      "\n",
      " EPOCH 15/400\n",
      "\t Training loss (epoch - mean):  0.056687837839126586\n",
      "\t Validation loss (epoch - mean): 0.056268243753212564\n",
      "\n",
      "\n",
      " EPOCH 16/400\n",
      "\t Training loss (epoch - mean):  0.055421631783246994\n",
      "\t Validation loss (epoch - mean): 0.03970215337826533\n",
      "\n",
      "\n",
      " EPOCH 17/400\n",
      "\t Training loss (epoch - mean):  0.05318293571472168\n",
      "\t Validation loss (epoch - mean): 0.041414000044398484\n",
      "\n",
      "\n",
      " EPOCH 18/400\n",
      "\t Training loss (epoch - mean):  0.04302649423480034\n",
      "\t Validation loss (epoch - mean): 0.04244455830887594\n",
      "\n",
      "\n",
      " EPOCH 19/400\n",
      "\t Training loss (epoch - mean):  0.04430998042225838\n",
      "\t Validation loss (epoch - mean): 0.0423996150394545\n",
      "\n",
      "\n",
      " EPOCH 20/400\n",
      "\t Training loss (epoch - mean):  0.04558754563331604\n",
      "\t Validation loss (epoch - mean): 0.044578625667007994\n",
      "\n",
      "\n",
      " EPOCH 21/400\n",
      "\t Training loss (epoch - mean):  0.039925999194383624\n",
      "\t Validation loss (epoch - mean): 0.03970396243768962\n",
      "\n",
      "\n",
      " EPOCH 22/400\n",
      "\t Training loss (epoch - mean):  0.036974357813596724\n",
      "\t Validation loss (epoch - mean): 0.027173935292050876\n",
      "\n",
      "\n",
      " EPOCH 23/400\n",
      "\t Training loss (epoch - mean):  0.03268736638128757\n",
      "\t Validation loss (epoch - mean): 0.029749524705310133\n",
      "\n",
      "\n",
      " EPOCH 24/400\n",
      "\t Training loss (epoch - mean):  0.03147990256547928\n",
      "\t Validation loss (epoch - mean): 0.028398478953564104\n",
      "\n",
      "\n",
      " EPOCH 25/400\n",
      "\t Training loss (epoch - mean):  0.029487421736121178\n",
      "\t Validation loss (epoch - mean): 0.023694318005854777\n",
      "\n",
      "\n",
      " EPOCH 26/400\n",
      "\t Training loss (epoch - mean):  0.026335408538579942\n",
      "\t Validation loss (epoch - mean): 0.01997251404657405\n",
      "\n",
      "\n",
      " EPOCH 27/400\n",
      "\t Training loss (epoch - mean):  0.029835863411426543\n",
      "\t Validation loss (epoch - mean): 0.028119106514458644\n",
      "\n",
      "\n",
      " EPOCH 28/400\n",
      "\t Training loss (epoch - mean):  0.02735257111489773\n",
      "\t Validation loss (epoch - mean): 0.02272828526676018\n",
      "\n",
      "\n",
      " EPOCH 29/400\n",
      "\t Training loss (epoch - mean):  0.023995548859238623\n",
      "\t Validation loss (epoch - mean): 0.023873292640386585\n",
      "\n",
      "\n",
      " EPOCH 30/400\n",
      "\t Training loss (epoch - mean):  0.025085997581481934\n",
      "\t Validation loss (epoch - mean): 0.022517745204745455\n",
      "\n",
      "\n",
      " EPOCH 31/400\n",
      "\t Training loss (epoch - mean):  0.025520232692360877\n",
      "\t Validation loss (epoch - mean): 0.018369284294981587\n",
      "\n",
      "\n",
      " EPOCH 32/400\n",
      "\t Training loss (epoch - mean):  0.02370608039200306\n",
      "\t Validation loss (epoch - mean): 0.02186895468014669\n",
      "\n",
      "\n",
      " EPOCH 33/400\n",
      "\t Training loss (epoch - mean):  0.021393708884716034\n",
      "\t Validation loss (epoch - mean): 0.019949191720522147\n",
      "\n",
      "\n",
      " EPOCH 34/400\n",
      "\t Training loss (epoch - mean):  0.01956611443310976\n",
      "\t Validation loss (epoch - mean): 0.02017609996007795\n",
      "\n",
      "\n",
      " EPOCH 35/400\n",
      "\t Training loss (epoch - mean):  0.02050571031868458\n",
      "\t Validation loss (epoch - mean): 0.021493177749513787\n",
      "\n",
      "\n",
      " EPOCH 36/400\n",
      "\t Training loss (epoch - mean):  0.018971630185842515\n",
      "\t Validation loss (epoch - mean): 0.016229417477239\n",
      "\n",
      "\n",
      " EPOCH 37/400\n",
      "\t Training loss (epoch - mean):  0.01831556372344494\n",
      "\t Validation loss (epoch - mean): 0.016726418092420838\n",
      "\n",
      "\n",
      " EPOCH 38/400\n",
      "\t Training loss (epoch - mean):  0.018132977932691575\n",
      "\t Validation loss (epoch - mean): 0.01801160260034289\n",
      "\n",
      "\n",
      " EPOCH 39/400\n",
      "\t Training loss (epoch - mean):  0.01663929969072342\n",
      "\t Validation loss (epoch - mean): 0.012362781632196238\n",
      "\n",
      "\n",
      " EPOCH 40/400\n",
      "\t Training loss (epoch - mean):  0.015042981877923012\n",
      "\t Validation loss (epoch - mean): 0.014294013208239042\n",
      "\n",
      "\n",
      " EPOCH 41/400\n",
      "\t Training loss (epoch - mean):  0.014112857729196548\n",
      "\t Validation loss (epoch - mean): 0.01599590184087766\n",
      "\n",
      "\n",
      " EPOCH 42/400\n",
      "\t Training loss (epoch - mean):  0.01559759620577097\n",
      "\t Validation loss (epoch - mean): 0.014867148832715255\n",
      "\n",
      "\n",
      " EPOCH 43/400\n",
      "\t Training loss (epoch - mean):  0.014906518161296844\n",
      "\t Validation loss (epoch - mean): 0.012334849868722736\n",
      "\n",
      "\n",
      " EPOCH 44/400\n",
      "\t Training loss (epoch - mean):  0.01392775885760784\n",
      "\t Validation loss (epoch - mean): 0.012490638109429323\n",
      "\n",
      "\n",
      " EPOCH 45/400\n",
      "\t Training loss (epoch - mean):  0.013420092314481736\n",
      "\t Validation loss (epoch - mean): 0.015405907751088268\n",
      "\n",
      "\n",
      " EPOCH 46/400\n",
      "\t Training loss (epoch - mean):  0.013392128981649876\n",
      "\t Validation loss (epoch - mean): 0.010514208002627748\n",
      "\n",
      "\n",
      " EPOCH 47/400\n",
      "\t Training loss (epoch - mean):  0.01304169837385416\n",
      "\t Validation loss (epoch - mean): 0.012069691019628117\n",
      "\n",
      "\n",
      " EPOCH 48/400\n",
      "\t Training loss (epoch - mean):  0.011668218486011028\n",
      "\t Validation loss (epoch - mean): 0.011502662766477132\n",
      "\n",
      "\n",
      " EPOCH 49/400\n",
      "\t Training loss (epoch - mean):  0.010811207816004753\n",
      "\t Validation loss (epoch - mean): 0.008799093791551174\n",
      "\n",
      "\n",
      " EPOCH 50/400\n",
      "\t Training loss (epoch - mean):  0.011319301836192609\n",
      "\t Validation loss (epoch - mean): 0.011149450626343172\n",
      "\n",
      "\n",
      " EPOCH 51/400\n",
      "\t Training loss (epoch - mean):  0.010733680054545402\n",
      "\t Validation loss (epoch - mean): 0.011985665226870395\n",
      "\n",
      "\n",
      " EPOCH 52/400\n",
      "\t Training loss (epoch - mean):  0.011067528277635574\n",
      "\t Validation loss (epoch - mean): 0.009468085676997633\n",
      "\n",
      "\n",
      " EPOCH 53/400\n",
      "\t Training loss (epoch - mean):  0.00962879192084074\n",
      "\t Validation loss (epoch - mean): 0.010243766273599752\n",
      "\n",
      "\n",
      " EPOCH 54/400\n",
      "\t Training loss (epoch - mean):  0.009058399870991708\n",
      "\t Validation loss (epoch - mean): 0.008566738229227608\n",
      "\n",
      "\n",
      " EPOCH 55/400\n",
      "\t Training loss (epoch - mean):  0.00958657991141081\n",
      "\t Validation loss (epoch - mean): 0.007618910454998804\n",
      "\n",
      "\n",
      " EPOCH 56/400\n",
      "\t Training loss (epoch - mean):  0.009762451611459255\n",
      "\t Validation loss (epoch - mean): 0.009684211691529391\n",
      "\n",
      "\n",
      " EPOCH 57/400\n",
      "\t Training loss (epoch - mean):  0.009536864794790744\n",
      "\t Validation loss (epoch - mean): 0.011059147768970976\n",
      "\n",
      "\n",
      " EPOCH 58/400\n",
      "\t Training loss (epoch - mean):  0.008962198905646802\n",
      "\t Validation loss (epoch - mean): 0.0075731836760941735\n",
      "\n",
      "\n",
      " EPOCH 59/400\n",
      "\t Training loss (epoch - mean):  0.008402328286319972\n",
      "\t Validation loss (epoch - mean): 0.008251712941118773\n",
      "\n",
      "\n",
      " EPOCH 60/400\n",
      "\t Training loss (epoch - mean):  0.0075058708898723125\n",
      "\t Validation loss (epoch - mean): 0.008305041610506027\n",
      "\n",
      "\n",
      " EPOCH 61/400\n",
      "\t Training loss (epoch - mean):  0.007651182357221842\n",
      "\t Validation loss (epoch - mean): 0.008483334683641009\n",
      "\n",
      "\n",
      " EPOCH 62/400\n",
      "\t Training loss (epoch - mean):  0.007225111220031976\n",
      "\t Validation loss (epoch - mean): 0.006548051743401571\n",
      "\n",
      "\n",
      " EPOCH 63/400\n",
      "\t Training loss (epoch - mean):  0.0074688193388283254\n",
      "\t Validation loss (epoch - mean): 0.006732237327749782\n",
      "\n",
      "\n",
      " EPOCH 64/400\n",
      "\t Training loss (epoch - mean):  0.006405028142035007\n",
      "\t Validation loss (epoch - mean): 0.006022322787952787\n",
      "\n",
      "\n",
      " EPOCH 65/400\n",
      "\t Training loss (epoch - mean):  0.006213143654167652\n",
      "\t Validation loss (epoch - mean): 0.0061999033864691576\n",
      "\n",
      "\n",
      " EPOCH 66/400\n",
      "\t Training loss (epoch - mean):  0.005769169330596924\n",
      "\t Validation loss (epoch - mean): 0.005929799148245675\n",
      "\n",
      "\n",
      " EPOCH 67/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training loss (epoch - mean):  0.005885407421737909\n",
      "\t Validation loss (epoch - mean): 0.005120856315346479\n",
      "\n",
      "\n",
      " EPOCH 68/400\n",
      "\t Training loss (epoch - mean):  0.006047454848885536\n",
      "\t Validation loss (epoch - mean): 0.005361946253075037\n",
      "\n",
      "\n",
      " EPOCH 69/400\n",
      "\t Training loss (epoch - mean):  0.005354845244437456\n",
      "\t Validation loss (epoch - mean): 0.005392014855076807\n",
      "\n",
      "\n",
      " EPOCH 70/400\n",
      "\t Training loss (epoch - mean):  0.004422827437520027\n",
      "\t Validation loss (epoch - mean): 0.00398079645473193\n",
      "\n",
      "\n",
      " EPOCH 71/400\n",
      "\t Training loss (epoch - mean):  0.005060135200619697\n",
      "\t Validation loss (epoch - mean): 0.003941442005096643\n",
      "\n",
      "\n",
      " EPOCH 72/400\n",
      "\t Training loss (epoch - mean):  0.004558425862342119\n",
      "\t Validation loss (epoch - mean): 0.005964369525479034\n",
      "\n",
      "\n",
      " EPOCH 73/400\n",
      "\t Training loss (epoch - mean):  0.004509247187525034\n",
      "\t Validation loss (epoch - mean): 0.004211716131589553\n",
      "\n",
      "\n",
      " EPOCH 74/400\n",
      "\t Training loss (epoch - mean):  0.0040460960939526554\n",
      "\t Validation loss (epoch - mean): 0.0035959493823688815\n",
      "\n",
      "\n",
      " EPOCH 75/400\n",
      "\t Training loss (epoch - mean):  0.003613634780049324\n",
      "\t Validation loss (epoch - mean): 0.003807699607816485\n",
      "\n",
      "\n",
      " EPOCH 76/400\n",
      "\t Training loss (epoch - mean):  0.0044267216697335245\n",
      "\t Validation loss (epoch - mean): 0.0035098893158066586\n",
      "\n",
      "\n",
      " EPOCH 77/400\n",
      "\t Training loss (epoch - mean):  0.00400694003328681\n",
      "\t Validation loss (epoch - mean): 0.004307159996081262\n",
      "\n",
      "\n",
      " EPOCH 78/400\n",
      "\t Training loss (epoch - mean):  0.0038388567976653577\n",
      "\t Validation loss (epoch - mean): 0.003663424098433213\n",
      "\n",
      "\n",
      " EPOCH 79/400\n",
      "\t Training loss (epoch - mean):  0.003211589762941003\n",
      "\t Validation loss (epoch - mean): 0.0038205098206433715\n",
      "\n",
      "\n",
      " EPOCH 80/400\n",
      "\t Training loss (epoch - mean):  0.003323803748935461\n",
      "\t Validation loss (epoch - mean): 0.003370625191661368\n",
      "\n",
      "\n",
      " EPOCH 81/400\n",
      "\t Training loss (epoch - mean):  0.003410907834768295\n",
      "\t Validation loss (epoch - mean): 0.003071820049839555\n",
      "\n",
      "\n",
      " EPOCH 82/400\n",
      "\t Training loss (epoch - mean):  0.0029311596881598234\n",
      "\t Validation loss (epoch - mean): 0.002968087227193966\n",
      "\n",
      "\n",
      " EPOCH 83/400\n",
      "\t Training loss (epoch - mean):  0.002914371248334646\n",
      "\t Validation loss (epoch - mean): 0.0027795611745108197\n",
      "\n",
      "\n",
      " EPOCH 84/400\n",
      "\t Training loss (epoch - mean):  0.002891164785251021\n",
      "\t Validation loss (epoch - mean): 0.0027613592559491544\n",
      "\n",
      "\n",
      " EPOCH 85/400\n",
      "\t Training loss (epoch - mean):  0.0027053807862102985\n",
      "\t Validation loss (epoch - mean): 0.0026374012105658583\n",
      "\n",
      "\n",
      " EPOCH 86/400\n",
      "\t Training loss (epoch - mean):  0.002629505284130573\n",
      "\t Validation loss (epoch - mean): 0.0026152168196704032\n",
      "\n",
      "\n",
      " EPOCH 87/400\n",
      "\t Training loss (epoch - mean):  0.0024274342926219107\n",
      "\t Validation loss (epoch - mean): 0.002089714238942914\n",
      "\n",
      "\n",
      " EPOCH 88/400\n",
      "\t Training loss (epoch - mean):  0.002381577715277672\n",
      "\t Validation loss (epoch - mean): 0.0023616664143736804\n",
      "\n",
      "\n",
      " EPOCH 89/400\n",
      "\t Training loss (epoch - mean):  0.00223377151414752\n",
      "\t Validation loss (epoch - mean): 0.0022329072889020764\n",
      "\n",
      "\n",
      " EPOCH 90/400\n",
      "\t Training loss (epoch - mean):  0.002082383772358298\n",
      "\t Validation loss (epoch - mean): 0.002104953449022705\n",
      "\n",
      "\n",
      " EPOCH 91/400\n",
      "\t Training loss (epoch - mean):  0.0021990838926285506\n",
      "\t Validation loss (epoch - mean): 0.0021111118987507927\n",
      "\n",
      "\n",
      " EPOCH 92/400\n",
      "\t Training loss (epoch - mean):  0.0019972956972196696\n",
      "\t Validation loss (epoch - mean): 0.0019613326931380956\n",
      "\n",
      "\n",
      " EPOCH 93/400\n",
      "\t Training loss (epoch - mean):  0.00187505257781595\n",
      "\t Validation loss (epoch - mean): 0.001639359077187769\n",
      "\n",
      "\n",
      " EPOCH 94/400\n",
      "\t Training loss (epoch - mean):  0.0018721311120316387\n",
      "\t Validation loss (epoch - mean): 0.0016451761385492029\n",
      "\n",
      "\n",
      " EPOCH 95/400\n",
      "\t Training loss (epoch - mean):  0.001647661393508315\n",
      "\t Validation loss (epoch - mean): 0.0019070407011227833\n",
      "\n",
      "\n",
      " EPOCH 96/400\n",
      "\t Training loss (epoch - mean):  0.0016982854111120104\n",
      "\t Validation loss (epoch - mean): 0.0016442121126894389\n",
      "\n",
      "\n",
      " EPOCH 97/400\n",
      "\t Training loss (epoch - mean):  0.0015375349204987288\n",
      "\t Validation loss (epoch - mean): 0.001530595698113757\n",
      "\n",
      "\n",
      " EPOCH 98/400\n",
      "\t Training loss (epoch - mean):  0.0015077862655743957\n",
      "\t Validation loss (epoch - mean): 0.0015306756429786315\n",
      "\n",
      "\n",
      " EPOCH 99/400\n",
      "\t Training loss (epoch - mean):  0.0012990610674023628\n",
      "\t Validation loss (epoch - mean): 0.0010797353460030206\n",
      "\n",
      "\n",
      " EPOCH 100/400\n",
      "\t Training loss (epoch - mean):  0.0013112535467371344\n",
      "\t Validation loss (epoch - mean): 0.0013063715120764793\n",
      "\n",
      "\n",
      " EPOCH 101/400\n",
      "\t Training loss (epoch - mean):  0.0012752392794936895\n",
      "\t Validation loss (epoch - mean): 0.0012798858566684236\n",
      "\n",
      "\n",
      " EPOCH 102/400\n",
      "\t Training loss (epoch - mean):  0.0012835657224059104\n",
      "\t Validation loss (epoch - mean): 0.0011641869146900563\n",
      "\n",
      "\n",
      " EPOCH 103/400\n",
      "\t Training loss (epoch - mean):  0.0011196830542758106\n",
      "\t Validation loss (epoch - mean): 0.0012762325544285209\n",
      "\n",
      "\n",
      " EPOCH 104/400\n",
      "\t Training loss (epoch - mean):  0.0011062131728976966\n",
      "\t Validation loss (epoch - mean): 0.000977381764066214\n",
      "\n",
      "\n",
      " EPOCH 105/400\n",
      "\t Training loss (epoch - mean):  0.001022521371487528\n",
      "\t Validation loss (epoch - mean): 0.0009538703047692639\n",
      "\n",
      "\n",
      " EPOCH 106/400\n",
      "\t Training loss (epoch - mean):  0.0010027778800576926\n",
      "\t Validation loss (epoch - mean): 0.0008573473974041568\n",
      "\n",
      "\n",
      " EPOCH 107/400\n",
      "\t Training loss (epoch - mean):  0.0008372063748538494\n",
      "\t Validation loss (epoch - mean): 0.0009067176303804135\n",
      "\n",
      "\n",
      " EPOCH 108/400\n",
      "\t Training loss (epoch - mean):  0.0008927082875743508\n",
      "\t Validation loss (epoch - mean): 0.0009171951977360221\n",
      "\n",
      "\n",
      " EPOCH 109/400\n",
      "\t Training loss (epoch - mean):  0.0008312318590469658\n",
      "\t Validation loss (epoch - mean): 0.0008041311680534954\n",
      "\n",
      "\n",
      " EPOCH 110/400\n",
      "\t Training loss (epoch - mean):  0.0008187290630303323\n",
      "\t Validation loss (epoch - mean): 0.0007265426856225105\n",
      "\n",
      "\n",
      " EPOCH 111/400\n",
      "\t Training loss (epoch - mean):  0.0008172965142875909\n",
      "\t Validation loss (epoch - mean): 0.0007040286348823661\n",
      "\n",
      "\n",
      " EPOCH 112/400\n",
      "\t Training loss (epoch - mean):  0.0007018579868599773\n",
      "\t Validation loss (epoch - mean): 0.0006924120117760817\n",
      "\n",
      "\n",
      " EPOCH 113/400\n",
      "\t Training loss (epoch - mean):  0.0006891391007229686\n",
      "\t Validation loss (epoch - mean): 0.0005764946884100743\n",
      "\n",
      "\n",
      " EPOCH 114/400\n",
      "\t Training loss (epoch - mean):  0.0006157883384730667\n",
      "\t Validation loss (epoch - mean): 0.0007142051516061753\n",
      "\n",
      "\n",
      " EPOCH 115/400\n",
      "\t Training loss (epoch - mean):  0.0006049800082109869\n",
      "\t Validation loss (epoch - mean): 0.0005514063308935951\n",
      "\n",
      "\n",
      " EPOCH 116/400\n",
      "\t Training loss (epoch - mean):  0.0005920806434005499\n",
      "\t Validation loss (epoch - mean): 0.0005096956632106664\n",
      "\n",
      "\n",
      " EPOCH 117/400\n",
      "\t Training loss (epoch - mean):  0.0005060111230704934\n",
      "\t Validation loss (epoch - mean): 0.0005264953835378153\n",
      "\n",
      "\n",
      " EPOCH 118/400\n",
      "\t Training loss (epoch - mean):  0.0005270218709483743\n",
      "\t Validation loss (epoch - mean): 0.0004720169624954693\n",
      "\n",
      "\n",
      " EPOCH 119/400\n",
      "\t Training loss (epoch - mean):  0.0005253967479802668\n",
      "\t Validation loss (epoch - mean): 0.0004977855416731874\n",
      "\n",
      "\n",
      " EPOCH 120/400\n",
      "\t Training loss (epoch - mean):  0.00046835069661028684\n",
      "\t Validation loss (epoch - mean): 0.0005129969407489819\n",
      "\n",
      "\n",
      " EPOCH 121/400\n",
      "\t Training loss (epoch - mean):  0.00043177581392228603\n",
      "\t Validation loss (epoch - mean): 0.0004297663582931025\n",
      "\n",
      "\n",
      " EPOCH 122/400\n",
      "\t Training loss (epoch - mean):  0.0004352710675448179\n",
      "\t Validation loss (epoch - mean): 0.0004885504965672071\n",
      "\n",
      "\n",
      " EPOCH 123/400\n",
      "\t Training loss (epoch - mean):  0.00039608171209692955\n",
      "\t Validation loss (epoch - mean): 0.0003933984540476268\n",
      "\n",
      "\n",
      " EPOCH 124/400\n",
      "\t Training loss (epoch - mean):  0.0003446525370236486\n",
      "\t Validation loss (epoch - mean): 0.00031399133508736493\n",
      "\n",
      "\n",
      " EPOCH 125/400\n",
      "\t Training loss (epoch - mean):  0.0003595862945076078\n",
      "\t Validation loss (epoch - mean): 0.0003582897223608636\n",
      "\n",
      "\n",
      " EPOCH 126/400\n",
      "\t Training loss (epoch - mean):  0.00031443761545233426\n",
      "\t Validation loss (epoch - mean): 0.0003302138709404923\n",
      "\n",
      "\n",
      " EPOCH 127/400\n",
      "\t Training loss (epoch - mean):  0.0003160433378070593\n",
      "\t Validation loss (epoch - mean): 0.00026942077762756296\n",
      "\n",
      "\n",
      " EPOCH 128/400\n",
      "\t Training loss (epoch - mean):  0.0003079380257986486\n",
      "\t Validation loss (epoch - mean): 0.00025984754469883433\n",
      "\n",
      "\n",
      " EPOCH 129/400\n",
      "\t Training loss (epoch - mean):  0.0002919589227531105\n",
      "\t Validation loss (epoch - mean): 0.00022557547671303934\n",
      "\n",
      "\n",
      " EPOCH 130/400\n",
      "\t Training loss (epoch - mean):  0.0002666261687409133\n",
      "\t Validation loss (epoch - mean): 0.000277324345432212\n",
      "\n",
      "\n",
      " EPOCH 131/400\n",
      "\t Training loss (epoch - mean):  0.0002586243790574372\n",
      "\t Validation loss (epoch - mean): 0.00023514171268132904\n",
      "\n",
      "\n",
      " EPOCH 132/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training loss (epoch - mean):  0.0002403679915005341\n",
      "\t Validation loss (epoch - mean): 0.00025134567598836434\n",
      "\n",
      "\n",
      " EPOCH 133/400\n",
      "\t Training loss (epoch - mean):  0.00021554066915996373\n",
      "\t Validation loss (epoch - mean): 0.00024127113390767725\n",
      "\n",
      "\n",
      " EPOCH 134/400\n",
      "\t Training loss (epoch - mean):  0.00021204424556344747\n",
      "\t Validation loss (epoch - mean): 0.00020874891320489796\n",
      "\n",
      "\n",
      " EPOCH 135/400\n",
      "\t Training loss (epoch - mean):  0.00019230414181947708\n",
      "\t Validation loss (epoch - mean): 0.00017834293962798808\n",
      "\n",
      "\n",
      " EPOCH 136/400\n",
      "\t Training loss (epoch - mean):  0.00018357616208959372\n",
      "\t Validation loss (epoch - mean): 0.0001782819967364416\n",
      "\n",
      "\n",
      " EPOCH 137/400\n",
      "\t Training loss (epoch - mean):  0.0001823671133024618\n",
      "\t Validation loss (epoch - mean): 0.00015744066678507202\n",
      "\n",
      "\n",
      " EPOCH 138/400\n",
      "\t Training loss (epoch - mean):  0.00017357171745970845\n",
      "\t Validation loss (epoch - mean): 0.0001277816516349617\n",
      "\n",
      "\n",
      " EPOCH 139/400\n",
      "\t Training loss (epoch - mean):  0.0001569270680192858\n",
      "\t Validation loss (epoch - mean): 0.00013015487224385332\n",
      "\n",
      "\n",
      " EPOCH 140/400\n",
      "\t Training loss (epoch - mean):  0.0001485815446358174\n",
      "\t Validation loss (epoch - mean): 0.00013015956852345493\n",
      "\n",
      "\n",
      " EPOCH 141/400\n",
      "\t Training loss (epoch - mean):  0.00014352472499012947\n",
      "\t Validation loss (epoch - mean): 0.00015180549524379883\n",
      "\n",
      "\n",
      " EPOCH 142/400\n",
      "\t Training loss (epoch - mean):  0.00014088048483245074\n",
      "\t Validation loss (epoch - mean): 0.0001288987414484454\n",
      "\n",
      "\n",
      " EPOCH 143/400\n",
      "\t Training loss (epoch - mean):  0.00012060279259458184\n",
      "\t Validation loss (epoch - mean): 8.47612834172288e-05\n",
      "\n",
      "\n",
      " EPOCH 144/400\n",
      "\t Training loss (epoch - mean):  0.00012180399935459718\n",
      "\t Validation loss (epoch - mean): 0.00014422996627583049\n",
      "\n",
      "\n",
      " EPOCH 145/400\n",
      "\t Training loss (epoch - mean):  0.00010694491211324931\n",
      "\t Validation loss (epoch - mean): 0.00011244822655371572\n",
      "\n",
      "\n",
      " EPOCH 146/400\n",
      "\t Training loss (epoch - mean):  9.80688477284275e-05\n",
      "\t Validation loss (epoch - mean): 7.543648594774977e-05\n",
      "\n",
      "\n",
      " EPOCH 147/400\n",
      "\t Training loss (epoch - mean):  9.75170114543289e-05\n",
      "\t Validation loss (epoch - mean): 9.240928046254223e-05\n",
      "\n",
      "\n",
      " EPOCH 148/400\n",
      "\t Training loss (epoch - mean):  8.256023720605299e-05\n",
      "\t Validation loss (epoch - mean): 9.445914859170105e-05\n",
      "\n",
      "\n",
      " EPOCH 149/400\n",
      "\t Training loss (epoch - mean):  8.53713252581656e-05\n",
      "\t Validation loss (epoch - mean): 6.64011617355501e-05\n",
      "\n",
      "\n",
      " EPOCH 150/400\n",
      "\t Training loss (epoch - mean):  7.948582497192546e-05\n",
      "\t Validation loss (epoch - mean): 8.262343997441658e-05\n",
      "\n",
      "\n",
      " EPOCH 151/400\n",
      "\t Training loss (epoch - mean):  7.279170531546698e-05\n",
      "\t Validation loss (epoch - mean): 6.39976605696652e-05\n",
      "\n",
      "\n",
      " EPOCH 152/400\n",
      "\t Training loss (epoch - mean):  6.942301406525076e-05\n",
      "\t Validation loss (epoch - mean): 6.390231467527031e-05\n",
      "\n",
      "\n",
      " EPOCH 153/400\n",
      "\t Training loss (epoch - mean):  6.650381983490661e-05\n",
      "\t Validation loss (epoch - mean): 6.639630435326176e-05\n",
      "\n",
      "\n",
      " EPOCH 154/400\n",
      "\t Training loss (epoch - mean):  6.784959841752425e-05\n",
      "\t Validation loss (epoch - mean): 4.839200087456041e-05\n",
      "\n",
      "\n",
      " EPOCH 155/400\n",
      "\t Training loss (epoch - mean):  6.184857556945644e-05\n",
      "\t Validation loss (epoch - mean): 6.392441819213112e-05\n",
      "\n",
      "\n",
      " EPOCH 156/400\n",
      "\t Training loss (epoch - mean):  5.181989763514139e-05\n",
      "\t Validation loss (epoch - mean): 5.005873941128928e-05\n",
      "\n",
      "\n",
      " EPOCH 157/400\n",
      "\t Training loss (epoch - mean):  5.19483772222884e-05\n",
      "\t Validation loss (epoch - mean): 5.0182788670022e-05\n",
      "\n",
      "\n",
      " EPOCH 158/400\n",
      "\t Training loss (epoch - mean):  4.478489136090502e-05\n",
      "\t Validation loss (epoch - mean): 4.295675465259398e-05\n",
      "\n",
      "\n",
      " EPOCH 159/400\n",
      "\t Training loss (epoch - mean):  3.942290786653757e-05\n",
      "\t Validation loss (epoch - mean): 4.265169274218506e-05\n",
      "\n",
      "\n",
      " EPOCH 160/400\n",
      "\t Training loss (epoch - mean):  3.9790250593796375e-05\n",
      "\t Validation loss (epoch - mean): 3.950619801898067e-05\n",
      "\n",
      "\n",
      " EPOCH 161/400\n",
      "\t Training loss (epoch - mean):  3.827551045105792e-05\n",
      "\t Validation loss (epoch - mean): 3.6777301551394624e-05\n",
      "\n",
      "\n",
      " EPOCH 162/400\n",
      "\t Training loss (epoch - mean):  3.559324904927053e-05\n",
      "\t Validation loss (epoch - mean): 2.9582961061693212e-05\n",
      "\n",
      "\n",
      " EPOCH 163/400\n",
      "\t Training loss (epoch - mean):  3.255881092627533e-05\n",
      "\t Validation loss (epoch - mean): 3.3626120478189436e-05\n",
      "\n",
      "\n",
      " EPOCH 164/400\n",
      "\t Training loss (epoch - mean):  3.218707133783028e-05\n",
      "\t Validation loss (epoch - mean): 3.572365528483754e-05\n",
      "\n",
      "\n",
      " EPOCH 165/400\n",
      "\t Training loss (epoch - mean):  2.979000310006086e-05\n",
      "\t Validation loss (epoch - mean): 2.4393713367941174e-05\n",
      "\n",
      "\n",
      " EPOCH 166/400\n",
      "\t Training loss (epoch - mean):  2.5734713926794938e-05\n",
      "\t Validation loss (epoch - mean): 2.8797375759805096e-05\n",
      "\n",
      "\n",
      " EPOCH 167/400\n",
      "\t Training loss (epoch - mean):  2.5224838827853092e-05\n",
      "\t Validation loss (epoch - mean): 2.5706792421429937e-05\n",
      "\n",
      "\n",
      " EPOCH 168/400\n",
      "\t Training loss (epoch - mean):  2.5344038294861094e-05\n",
      "\t Validation loss (epoch - mean): 2.3990716217812928e-05\n",
      "\n",
      "\n",
      " EPOCH 169/400\n",
      "\t Training loss (epoch - mean):  2.2396050553652458e-05\n",
      "\t Validation loss (epoch - mean): 2.3229613640538408e-05\n",
      "\n",
      "\n",
      " EPOCH 170/400\n",
      "\t Training loss (epoch - mean):  2.0796714306925423e-05\n",
      "\t Validation loss (epoch - mean): 2.1971852988899434e-05\n",
      "\n",
      "\n",
      " EPOCH 171/400\n",
      "\t Training loss (epoch - mean):  1.8467831250745802e-05\n",
      "\t Validation loss (epoch - mean): 1.4264154905978353e-05\n",
      "\n",
      "\n",
      " EPOCH 172/400\n",
      "\t Training loss (epoch - mean):  1.758320904627908e-05\n",
      "\t Validation loss (epoch - mean): 1.3669209466265687e-05\n",
      "\n",
      "\n",
      " EPOCH 173/400\n",
      "\t Training loss (epoch - mean):  1.645984739298001e-05\n",
      "\t Validation loss (epoch - mean): 1.779019271730645e-05\n",
      "\n",
      "\n",
      " EPOCH 174/400\n",
      "\t Training loss (epoch - mean):  1.4513977657770737e-05\n",
      "\t Validation loss (epoch - mean): 1.683980134986725e-05\n",
      "\n",
      "\n",
      " EPOCH 175/400\n",
      "\t Training loss (epoch - mean):  1.5564460045425222e-05\n",
      "\t Validation loss (epoch - mean): 1.5213039062550803e-05\n",
      "\n",
      "\n",
      " EPOCH 176/400\n",
      "\t Training loss (epoch - mean):  1.410676159139257e-05\n",
      "\t Validation loss (epoch - mean): 1.169951743413077e-05\n",
      "\n",
      "\n",
      " EPOCH 177/400\n",
      "\t Training loss (epoch - mean):  1.1387583617761265e-05\n",
      "\t Validation loss (epoch - mean): 1.1195956706111981e-05\n",
      "\n",
      "\n",
      " EPOCH 178/400\n",
      "\t Training loss (epoch - mean):  1.0899415428866632e-05\n",
      "\t Validation loss (epoch - mean): 1.1220899738904858e-05\n",
      "\n",
      "\n",
      " EPOCH 179/400\n",
      "\t Training loss (epoch - mean):  1.078203713404946e-05\n",
      "\t Validation loss (epoch - mean): 9.837891466990782e-06\n",
      "\n",
      "\n",
      " EPOCH 180/400\n",
      "\t Training loss (epoch - mean):  9.306964511779369e-06\n",
      "\t Validation loss (epoch - mean): 8.10989106738855e-06\n",
      "\n",
      "\n",
      " EPOCH 181/400\n",
      "\t Training loss (epoch - mean):  9.186003080685622e-06\n",
      "\t Validation loss (epoch - mean): 7.475874173556523e-06\n",
      "\n",
      "\n",
      " EPOCH 182/400\n",
      "\t Training loss (epoch - mean):  7.88023617133149e-06\n",
      "\t Validation loss (epoch - mean): 8.276110901427254e-06\n",
      "\n",
      "\n",
      " EPOCH 183/400\n",
      "\t Training loss (epoch - mean):  7.801377250871155e-06\n",
      "\t Validation loss (epoch - mean): 7.220746851119818e-06\n",
      "\n",
      "\n",
      " EPOCH 184/400\n",
      "\t Training loss (epoch - mean):  6.952566036488861e-06\n",
      "\t Validation loss (epoch - mean): 7.443590524667585e-06\n",
      "\n",
      "\n",
      " EPOCH 185/400\n",
      "\t Training loss (epoch - mean):  6.576634586963337e-06\n",
      "\t Validation loss (epoch - mean): 6.6383457928751304e-06\n",
      "\n",
      "\n",
      " EPOCH 186/400\n",
      "\t Training loss (epoch - mean):  5.918267561355606e-06\n",
      "\t Validation loss (epoch - mean): 6.569167353784499e-06\n",
      "\n",
      "\n",
      " EPOCH 187/400\n",
      "\t Training loss (epoch - mean):  5.704675641027279e-06\n",
      "\t Validation loss (epoch - mean): 5.44938054608889e-06\n",
      "\n",
      "\n",
      " EPOCH 188/400\n",
      "\t Training loss (epoch - mean):  5.105365198687651e-06\n",
      "\t Validation loss (epoch - mean): 5.969555733740817e-06\n",
      "\n",
      "\n",
      " EPOCH 189/400\n",
      "\t Training loss (epoch - mean):  4.592917366608162e-06\n",
      "\t Validation loss (epoch - mean): 4.657147232043452e-06\n",
      "\n",
      "\n",
      " EPOCH 190/400\n",
      "\t Training loss (epoch - mean):  4.757776150654536e-06\n",
      "\t Validation loss (epoch - mean): 4.287234169453313e-06\n",
      "\n",
      "\n",
      " EPOCH 191/400\n",
      "\t Training loss (epoch - mean):  3.692021482493146e-06\n",
      "\t Validation loss (epoch - mean): 4.065121807021821e-06\n",
      "\n",
      "\n",
      " EPOCH 192/400\n",
      "\t Training loss (epoch - mean):  3.817239439740661e-06\n",
      "\t Validation loss (epoch - mean): 3.378125106114101e-06\n",
      "\n",
      "\n",
      " EPOCH 193/400\n",
      "\t Training loss (epoch - mean):  3.6088812976231567e-06\n",
      "\t Validation loss (epoch - mean): 3.511126760471762e-06\n",
      "\n",
      "\n",
      " EPOCH 194/400\n",
      "\t Training loss (epoch - mean):  3.338460874147131e-06\n",
      "\t Validation loss (epoch - mean): 3.0871072896874987e-06\n",
      "\n",
      "\n",
      " EPOCH 195/400\n",
      "\t Training loss (epoch - mean):  2.7397852591093397e-06\n",
      "\t Validation loss (epoch - mean): 2.8121212592400287e-06\n",
      "\n",
      "\n",
      " EPOCH 196/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Training loss (epoch - mean):  2.65181533904979e-06\n",
      "\t Validation loss (epoch - mean): 2.6711525069564254e-06\n",
      "\n",
      "\n",
      " EPOCH 197/400\n",
      "\t Training loss (epoch - mean):  2.3897991468402326e-06\n",
      "\t Validation loss (epoch - mean): 2.511068774284689e-06\n",
      "\n",
      "\n",
      " EPOCH 198/400\n",
      "\t Training loss (epoch - mean):  2.2703429976900224e-06\n",
      "\t Validation loss (epoch - mean): 1.6998715286439755e-06\n",
      "\n",
      "\n",
      " EPOCH 199/400\n",
      "\t Training loss (epoch - mean):  2.0477386215134173e-06\n",
      "\t Validation loss (epoch - mean): 1.8909834753469236e-06\n",
      "\n",
      "\n",
      " EPOCH 200/400\n",
      "\t Training loss (epoch - mean):  1.963896056622616e-06\n",
      "\t Validation loss (epoch - mean): 1.8456179673159357e-06\n",
      "\n",
      "\n",
      " EPOCH 201/400\n",
      "\t Training loss (epoch - mean):  1.7255674038096914e-06\n",
      "\t Validation loss (epoch - mean): 2.020959432877919e-06\n",
      "\n",
      "\n",
      " EPOCH 202/400\n",
      "\t Training loss (epoch - mean):  1.6275666666842882e-06\n",
      "\t Validation loss (epoch - mean): 1.307867169495822e-06\n",
      "\n",
      "\n",
      " EPOCH 203/400\n",
      "\t Training loss (epoch - mean):  1.6832928622534382e-06\n",
      "\t Validation loss (epoch - mean): 1.4662547964811035e-06\n",
      "\n",
      "\n",
      " EPOCH 204/400\n",
      "\t Training loss (epoch - mean):  1.4220412140275585e-06\n",
      "\t Validation loss (epoch - mean): 1.510308508308809e-06\n",
      "\n",
      "\n",
      " EPOCH 205/400\n",
      "\t Training loss (epoch - mean):  1.1748444876502618e-06\n",
      "\t Validation loss (epoch - mean): 1.305751826002072e-06\n",
      "\n",
      "\n",
      " EPOCH 206/400\n",
      "\t Training loss (epoch - mean):  1.1814725439762697e-06\n",
      "\t Validation loss (epoch - mean): 1.0583569697132439e-06\n",
      "\n",
      "\n",
      " EPOCH 207/400\n",
      "\t Training loss (epoch - mean):  1.0905223916779506e-06\n",
      "\t Validation loss (epoch - mean): 1.0674781715130094e-06\n",
      "\n",
      "\n",
      " EPOCH 208/400\n",
      "\t Training loss (epoch - mean):  1.0428297514408769e-06\n",
      "\t Validation loss (epoch - mean): 9.923498202923658e-07\n",
      "\n",
      "\n",
      " EPOCH 209/400\n",
      "\t Training loss (epoch - mean):  1.0129209158549201e-06\n",
      "\t Validation loss (epoch - mean): 8.812409571335362e-07\n",
      "\n",
      "\n",
      " EPOCH 210/400\n",
      "\t Training loss (epoch - mean):  8.396702696700231e-07\n",
      "\t Validation loss (epoch - mean): 9.188191574391502e-07\n",
      "\n",
      "\n",
      " EPOCH 211/400\n",
      "\t Training loss (epoch - mean):  7.537113219768799e-07\n",
      "\t Validation loss (epoch - mean): 9.430757570805721e-07\n",
      "\n",
      "\n",
      " EPOCH 212/400\n",
      "\t Training loss (epoch - mean):  7.376783059953596e-07\n",
      "\t Validation loss (epoch - mean): 6.576629282391426e-07\n",
      "\n",
      "\n",
      " EPOCH 213/400\n",
      "\t Training loss (epoch - mean):  6.308998536042054e-07\n",
      "\t Validation loss (epoch - mean): 4.73390860780746e-07\n",
      "\n",
      "\n",
      " EPOCH 214/400\n",
      "\t Training loss (epoch - mean):  6.026958885740896e-07\n",
      "\t Validation loss (epoch - mean): 5.236177077270766e-07\n",
      "\n",
      "\n",
      " EPOCH 215/400\n",
      "\t Training loss (epoch - mean):  4.792064487446623e-07\n",
      "\t Validation loss (epoch - mean): 4.0839984560113065e-07\n",
      "\n",
      "\n",
      " EPOCH 216/400\n",
      "\t Training loss (epoch - mean):  4.509486302595178e-07\n",
      "\t Validation loss (epoch - mean): 5.281779478133345e-07\n",
      "\n",
      "\n",
      " EPOCH 217/400\n",
      "\t Training loss (epoch - mean):  4.7517257826257266e-07\n",
      "\t Validation loss (epoch - mean): 3.8104387131167344e-07\n",
      "\n",
      "\n",
      " EPOCH 218/400\n",
      "\t Training loss (epoch - mean):  4.41703565456919e-07\n",
      "\t Validation loss (epoch - mean): 4.302771695395292e-07\n",
      "\n",
      "\n",
      " EPOCH 219/400\n",
      "\t Training loss (epoch - mean):  3.956324064802175e-07\n",
      "\t Validation loss (epoch - mean): 2.870858519255288e-07\n",
      "\n",
      "\n",
      " EPOCH 220/400\n",
      "\t Training loss (epoch - mean):  3.347776839746075e-07\n",
      "\t Validation loss (epoch - mean): 2.72104584538172e-07\n",
      "\n",
      "\n",
      " EPOCH 221/400\n",
      "\t Training loss (epoch - mean):  3.101244317349483e-07\n",
      "\t Validation loss (epoch - mean): 2.1755469839335658e-07\n",
      "\n",
      "\n",
      " EPOCH 222/400\n",
      "\t Training loss (epoch - mean):  2.649770777907179e-07\n",
      "\t Validation loss (epoch - mean): 2.7299588935311013e-07\n",
      "\n",
      "\n",
      " EPOCH 223/400\n",
      "\t Training loss (epoch - mean):  2.406802877885639e-07\n",
      "\t Validation loss (epoch - mean): 2.0089143840402677e-07\n",
      "\n",
      "\n",
      " EPOCH 224/400\n",
      "\t Training loss (epoch - mean):  2.2151157850203162e-07\n",
      "\t Validation loss (epoch - mean): 1.7561095502594466e-07\n",
      "\n",
      "\n",
      " EPOCH 225/400\n",
      "\t Training loss (epoch - mean):  2.2326466080357933e-07\n",
      "\t Validation loss (epoch - mean): 2.0488770179279047e-07\n",
      "\n",
      "\n",
      " EPOCH 226/400\n",
      "\t Training loss (epoch - mean):  1.808337145803307e-07\n",
      "\t Validation loss (epoch - mean): 1.772178183822664e-07\n",
      "\n",
      "\n",
      " EPOCH 227/400\n",
      "\t Training loss (epoch - mean):  1.648416059651936e-07\n",
      "\t Validation loss (epoch - mean): 1.6259401310915497e-07\n",
      "\n",
      "\n",
      " EPOCH 228/400\n",
      "\t Training loss (epoch - mean):  1.5625145124431584e-07\n",
      "\t Validation loss (epoch - mean): 1.8640847558209222e-07\n",
      "\n",
      "\n",
      " EPOCH 229/400\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#%% Train network\n",
    "\n",
    "# Define losses containers\n",
    "train_loss_epochs = []\n",
    "val_loss_epochs = []\n",
    "\n",
    "for epoch in range(params['num_epochs']):\n",
    "    print('\\n\\n EPOCH %d/%d' % (epoch + 1, params['num_epochs']))\n",
    "    \n",
    "    # Set training mode\n",
    "    net.train()\n",
    "    # Define losses container for one epoch\n",
    "    train_loss_log = []\n",
    "    \n",
    "    # Iterate batches\n",
    "    for batch_sample in train_dataloader:\n",
    "        # Extract batch\n",
    "        batch = batch_sample.long().to(device)\n",
    "        # Update network\n",
    "        batch_loss = net.train_batch(batch, loss_fn, optimizer)\n",
    "        train_loss_log.append(batch_loss)\n",
    "        # print('\\t Training loss (single batch):', batch_loss)\n",
    "        \n",
    "    print('\\t Training loss (epoch - mean): ', np.mean(train_loss_log) )\n",
    "    train_loss_epochs.append(np.mean(train_loss_log))\n",
    "    \n",
    "    # Set evaluation mode\n",
    "    net.eval()\n",
    "    val_loss_log = []\n",
    "    with torch.no_grad():\n",
    "        for batch_sample in test_dataloader:\n",
    "            batch = batch_sample.long().to(device)\n",
    "            val_loss = net.test_batch(batch, loss_fn)\n",
    "            val_loss_log.append(val_loss)\n",
    "            \n",
    "        print('\\t Validation loss (epoch - mean):', np.mean(val_loss_log))\n",
    "        val_loss_epochs.append(np.mean(val_loss_log))\n",
    "        \n",
    "    # Early stopping\n",
    "    # if epoch>200 and abs(val_loss_epochs[-1] - val_loss_epochs[-200]) < 1e-10:\n",
    "    #    break\n",
    "    \n",
    "losses = { 'train': train_loss_epochs, 'val':  val_loss_epochs, 'params' : params }\n",
    "\n",
    "# Save losses dictionary\n",
    "with open(res_path + \"/\" + out_dir, 'wb') as f:\n",
    "    pickle.dump(losses, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "# Save model \n",
    "torch.save(net.state_dict(), res_path + \"/state_\" + out_dir + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1MSNBDkx39Mg"
   },
   "outputs": [],
   "source": [
    "# Plot losses\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.semilogy(train_loss_epochs, label='Train loss')\n",
    "plt.semilogy(val_loss_epochs, label='Validation loss', linestyle='dashed')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(images_path+f\"/model_losses_{crop_len}_{min_len}\"+\"_{}_{}.png\".format(params['lr'],params['wd']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "seed = 'When you are alone in the middle of the sea'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embedding\n",
    "\n",
    "# Load embeddings\n",
    "with open('./data/embeddings', 'rb') as f:\n",
    "    embeddings = pickle.load(f)\n",
    "    \n",
    "# Get list of words\n",
    "words = [*embeddings.keys()]\n",
    "# Get vectors as float tensor\n",
    "vectors = torch.tensor([*embeddings.values()], dtype=torch.float)\n",
    "    \n",
    "\n",
    "# Load hyperparameters\n",
    "with open(res_path + \"/\" + out_dir, 'rb') as f:\n",
    "    params = pickle.load(f)\n",
    "    params = params['params']\n",
    "\n",
    "# Embedding matrix\n",
    "X = np.array(list(embeddings.values()))\n",
    "    \n",
    "# Set device\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Load model\n",
    "state = torch.load(res_path + \"/state_\" + out_dir + '.pth', map_location = device)\n",
    "\n",
    "net = Network(vocab_size = len(embeddings.keys()),\n",
    "              embedding_dim = 50,\n",
    "              hidden_units = params['hidden_units'],\n",
    "              layers_num = params['layers_num'],\n",
    "              hidden_type = 'LSTM',\n",
    "              trained_embeddings = wor,\n",
    "              dropout_prob = params['dropout_prob']\n",
    "             )\n",
    "\n",
    "net.load_state_dict(state)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WordToVector\n",
    "\n",
    "w2v = WordToVector(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation mode\n",
    "net.eval()\n",
    "\n",
    "print(seed, end=' ', flush=True)\n",
    "\n",
    "net_state = None\n",
    "with torch.no_grad():\n",
    "    # Generate n words\n",
    "    for i in range(15):\n",
    "        # Transform words in the corresponding indices\n",
    "        seed_encoded = torch.tensor(w2v(seed.lower()))\n",
    "        # Reshape: batch-like shape\n",
    "        seed_encoded = torch.reshape(seed_encoded, (1, -1))\n",
    "        # Move to the selected device\n",
    "        seed_encoded.to(device)\n",
    "        # Forward step\n",
    "        net_out, net_state = net(seed_encoded, net_state)\n",
    "\n",
    "        closest_index = np.argmin(np.linalg.norm((X - net_out[:, -1, :].to('cpu').numpy()[0]), axis = 1))\n",
    "        closest_word = words[closest_index]\n",
    "        seed += ' ' + closest_word\n",
    "        print(closest_word, end=' ', flush=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
